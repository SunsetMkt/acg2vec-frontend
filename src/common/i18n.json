{
	"zh": {
		"abstract": "ACG2vec全称为Anime Comics Games to vector。将持续维护一些基于二次元相关的深度学习领域实践与探索。",
		"model_list": "模型列表",
		"acgvoc2vec_intro": "基于从维基百科动漫列表、萌娘百科、Bangumi、pixiv、AnimeList等来源获取清洗处理抽取的510w语句对微调的sentence-transformers模型，生成二次元相关文本的特征向量，用于各种下游任务（标签推荐，标签搜索，推荐系统等）可以使用<a href=\"https://huggingface.co/OysterQAQ/ACGVoc2vec\" target=\"_blank\" class=\"url\" >Huggingface</a>在线体验",
		"dclip_intro": "使用danburoo2021数据集对clip（ViT-L/14）模型进行微调。可以使用<a href=\"https://huggingface.co/OysterQAQ/DanbooruCLIP\" target=\"_blank\" class=\"url\" >Huggingface</a>在线体验。",
		"pix2score_intro": "基于ResNet101的多任务分类模型，用于分段预测动漫插图的收藏数、浏览数与情色级别。",
		"illust2vec_intro": "从<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a>模型去除预测头并对末尾层做均值池化的图片语义特征抽取模型。",
		"cugan_tf_intro":"当前最优秀的动漫领域超分模型之一<a href=\"https://github.com/bilibili/ailab/tree/main/Real-CUGAN\" target=\"_blank\" class=\"url\" >Real-CUGAN</a>的tensorflow实现，依赖<a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a>框架完成自适应后端的能运行在浏览器上的动漫超分工具。",
		"acgvoc2vec_detail": "使用<a href=\"https://www.sbert.net/\" target=\"_blank\" class=\"url\" >Sentence-Transformers</a>（distiluse-base-multilingual-cased-v2预训练权重），以5e-5的学习率在动漫相关多角度（翻译，问答）语句对数据集下进行微调，损失函数为MultipleNegativesRankingLoss。数据集主要包括：Bangumi、pixiv、AnimeList、维基百科、moegirl。",
		"dclip_detail": "使用<a href=\"https://gwern.net/danbooru2021\" target=\"_blank\" class=\"url\" >danburoo2021</a>数据集对<a href=\"https://github.com/openai/CLIP\" target=\"_blank\" class=\"url\" >CLIP</a>（ViT-L/14预训练权重）模型进行微调。0-3 epoch学习率为4e-6，权重衰减为1e-3、4-8 epoch学习率为1e-6，权重衰减为1e-3，最终平均loss在5e-1左右。",
		"pix2score_detail": "基于ResNet101的多任务分类模型，用于分段预测动漫插图的收藏数、浏览数与情色级别。以 1e-3 的学习率在动漫插画数据集下进行混合精度训练，输入尺寸为224x224。",
		"illust2vec_detail": "<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a>的输入层至activation_96层作为特征抽取器，均值池化后的图片语义特征抽取模型。",
		"cugan_tf_detail":"当前最优秀的动漫领域超分模型之一<a href=\"https://github.com/bilibili/ailab/tree/main/Real-CUGAN\" target=\"_blank\" class=\"url\" >Real-CUGAN</a>的tensorflow实现，依赖<a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a>框架完成自适应后端的能运行在浏览器上的动漫超分工具。</br>原版实现分为切块后超分与整图超分，两种都以实现，但切块超分版本转为tfjs模型后在网页运行不正常，已向<a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a>仓库提交<a href=\"https://github.com/tensorflow/tfjs/issues/7960\" target=\"_blank\" class=\"url\" >issue</a>。目前预览版本是整图超分版本，由于内存限制，限制了原始图片大小（512x512以内），后续issue解决将发布切块超分，大概率将不会有限制。",
		"to_be_continue": "未完待续",
		"continue": "将持续开发ACG相关深度学习应用",
		"star": "⭐⭐⭐",
		"star_detail": "如果acg2vec对你有帮助，请点个star支持一下～",
		"acgvoc2vec_input": "输入标签，搜索出近似标签",
		"dclip_input": "输入英文描述，搜索出符合描述的插画",
		"image_select": "点击选择图片"

	},
	"en": {
		"abstract": "ACG2vec, the full name of which is Anime Comics Games to Vector, will continue to maintain some practices and explorations in the field of deep learning related to ACGN (Animation, Comic, Game, Novel) content.",
		"model_list": "model list",
		"acgvoc2vec_intro": "Based on the 510 million sentences extracted, cleaned, and processed from sources like Wikipedia's anime list, Moe Girl Encyclopedia, Bangumi, pixiv, AnimeList, etc., a sentence-transformers model has been fine-tuned to generate feature vectors for ACGN content. These feature vectors can be utilized for various downstream tasks such as tag recommendation, tag search, recommendation systems, etc. You can experience the model online using the <a href=\"https://huggingface.co/OysterQAQ/ACGVoc2vec\" target=\"_blank\" class=\"url\" >Huggingface</a> platform.",
		"dclip_intro": "Using the danburoo2021 dataset to fine-tune the clip (ViT-L/14) model. You can use the <a href=\"https://huggingface.co/OysterQAQ/DanbooruCLIP\" target=\"_blank\" class=\"url\" >Huggingface</a> online experience.",
		"pix2score_intro": "A multi-task classification model based on ResNet101 is used for segmented prediction of the number of favorites, views, and the maturity level of anime illustrations.",
		"illust2vec_intro": "A model for extracting semantic image features from <a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> by removing the prediction head and applying mean pooling to the final layer.",
		"cugan_tf_intro":"One of the current leading super-resolution models in the field of anime, <a href=\"https://github.com/bilibili/ailab/tree/main/Real-CUGAN\" target=\"_blank\" class=\"url\" >Real-CUGAN</a>, has been implemented in TensorFlow. This implementation relies on the <a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a> framework to achieve adaptive backend support, allowing it to run as an anime super-resolution tool in web browsers.",
		"acgvoc2vec_detail": "Using <a href=\"https://www.sbert.net/\" target=\"_blank\" class=\"url\" >Sentence-Transformers</a> with the distiluse-base-multilingual-cased-v2 pretrained weights, fine-tune the model on a dataset containing anime-related multi-angle (translation, question-answering) sentence pairs with a learning rate of 5e-5. The loss function used is MultipleNegativesRankingLoss. The dataset primarily includes data from Bangumi, pixiv, AnimeList, Wikipedia, and moegirl.",
		"dclip_detail": "Using the <a href=\"https://gwern.net/danbooru2021\" target=\"_blank\" class=\"url\" >danburoo2021</a> dataset, fine-tune the <a href=\"https://github.com/openai/CLIP\" target=\"_blank\" class=\"url\" >CLIP</a> model with ViT-L/14 pretrained weights. For the first 0-3 epochs, use a learning rate of 4e-6 and weight decay of 1e-3. For the next 4-8 epochs, use a learning rate of 1e-6 and weight decay of 1e-3. The final average loss should be around 5e-1.",
		"pix2score_detail": "A multi-task classification model based on ResNet101 is used for segmented prediction of the number of favorites, views, and the maturity level of anime illustrations. The model is trained using mixed precision training with a learning rate of 1e-3 on an anime illustration dataset, and the input size is set to 224x224.",
		"illust2vec_detail": "The feature extractor of <a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> consists of the input layer up to activation_96 layer, and it serves as a model for extracting semantic image features. These features are obtained by applying mean pooling to the output of the activation_96 layer.",
		"cugan_tf_detail":"One of the current leading super-resolution models in the field of anime, <a href=\"https://github.com/bilibili/ailab/tree/main/Real-CUGAN\" target=\"_blank\" class=\"url\" >Real-CUGAN</a>, has been implemented in TensorFlow. This implementation relies on the <a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a> framework to achieve adaptive backend support, allowing it to run as an anime super-resolution tool in web browsers.</br>The original implementation includes both chunk-based super-resolution and whole-image super-resolution. While both have been implemented, the chunk-based super-resolution version, when converted to a tfjs model, experiences issues when running on web pages. An <a href=\"https://github.com/tensorflow/tfjs/issues/7960\" target=\"_blank\" class=\"url\" >issue</a> has been submitted to the <a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a> repository for this matter (see here).</br>Currently, the preview version only supports whole-image super-resolution and imposes a size limitation on the original images (up to 512x512) due to memory constraints. Once the issue is resolved, there will likely be an update that includes the chunk-based super-resolution without such limitations.",
		"to_be_continue": "To be continued",
		"continue": "Continuous development of ACG (Anime, Comics, Games) related deep learning applications will be pursued",
		"star": "⭐⭐⭐",
		"star_detail": "If ACG2vec has been helpful to you, please show your support by giving it a star~",
		"acgvoc2vec_input": "Input a label, search for approximate labels",
		"dclip_input": "Input an English description, search for illustrations",
		"image_select": "Click to select an image"
	},
	"jp": {
		"abstract": "ACG2vec の正式名は、アニメ・コミック・ゲーム・トゥ・ベクターです。二次元相関に基づく深層学習の分野での実践と探求は引き続き維持されます。",
		"model_list": "モデルリスト",
		"acgvoc2vec_intro": "ウィキペディアのアニメリスト、萌えガールペディア、バングミ、ピクシブ、アニメリストなどのソースから抽出した510wの文を取得してクリーニングおよび処理することで微調整された文変換モデルに基づいて、さまざまな下流向けに二次元関連テキストの特徴ベクトルが生成されます。タスク (ラベル) レコメンデーション、タグ検索、レコメンデーション システムなど) <a href=\"https://huggingface.co/OysterQAQ/ACGVoc2vec\" target=\"_blank\" class=\"url\" を使用できます>ハグフェイス</a>オンライン体験。",
		"dclip_intro": "クリップ (ViT-L/14) モデルは、danburoo2021 データセットを使用して微調整されています。 <a href=\"https://huggingface.co/OysterQAQ/DanbooruCLIP\" target=\"_blank\" class=\"url\" >Huggingface</a> を使用してオンラインで体験できます。",
		"pix2score_intro": "ResNet101 に基づくマルチタスク分類モデル。アニメーション イラストのコレクション数、閲覧数、エロレベルを部分的に予測するために使用されます。",
		"illust2vec_intro": "<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> モデルから予測ヘッドを削除し、最後の予測ヘッドを平均しますレイヤー プールされた画像セマンティック特徴抽出モデル。",
		"cugan_tf_intro":"現在のアニメ分野で最も優れた超解像モデルの1つである<a href=\"https://github.com/bilibili/ailab/tree/main/Real-CUGAN\" target=\"_blank\" class=\"url\" >Real-CUGAN</a>は、TensorFlowで実装されており、<a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a>フレームワークに依存しています。これにより、ブラウザで実行できるアニメの超解像ツールが自動バックエンドを実現しています。",
		"acgvoc2vec_detail": "<a href=\"https://www.sbert.net/\" target=\"_blank\" class=\"url\" >Sentence-Transformers</a> を使用します (distiluse-base-multilingual-cased- v2 事前トレーニング重み)、アニメーション関連のマルチアングル (翻訳、質疑応答) 文のデータセットを微調整するための学習率は 5e-5 で、損失関数は MultipleNegativesRankingLoss です。データセットには主に、バングミ、ピクシブ、アニメリスト、ウィキペディア、moegirl が含まれています。",
		"dclip_detail": "<a href=\"https://gwern.net/danbooru2021\" target=\"_blank\" class=\"url\" >danburoo2021</a> データセットを <a href=\"https:/ に使用します。 /github.com/openai/CLIP\" target=\"_blank\" class=\"url\" >CLIP</a> (ViT-L/14 事前トレーニング済み重み) モデルを微調整します。 0 ～ 3 エポックの学習レートは 4e-6、重み減衰は 1e-3、4 ～ 8 エポックの学習レートは 1e-6、重み減衰は 1e-3、最終的な平均損失は約 5e -1。",
		"pix2score_detail": "ResNet101 に基づくマルチタスク分類モデル。アニメーション イラストのコレクション数、閲覧数、エロレベルを部分的に予測するために使用されます。アニメ イラスト データセットに対する混合精度トレーニング (学習率 1e-3、入力サイズ 224x224)。",
		"illust2vec_detail": "<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> の入力層から activity_96 層までが特徴抽出器として使用され、平均プーリング後の画像意味特徴抽出モデルとして使用されます。",
		"cugan_tf_detail":"現在のアニメ分野で最も優れた超解像モデルの1つである<a href=\"https://github.com/bilibili/ailab/tree/main/Real-CUGAN\" target=\"_blank\" class=\"url\" >Real-CUGAN</a>は、TensorFlowで実装されており、<a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a>フレームワークに依存しています。これにより、ブラウザで実行できるアニメの超解像ツールが自動バックエンドを実現しています。</br>元の実装には、チャンクベースの超解像と全画像超解像の2つのバージョンが含まれています。両方が実装されていますが、チャンクベースの超解像バージョンは、tfjsモデルに変換した後にWebページで正常に動作しない問題が発生しています。この問題については、<a href=\"https://github.com/tensorflow/tfjs\" target=\"_blank\" class=\"url\" >tfjs</a>リポジトリに<a href=\"https://github.com/tensorflow/tfjs/issues/7960\" target=\"_blank\" class=\"url\" >issue</a>が提出されています（こちらを参照）。</br>現時点では、プレビューバージョンでは全画像超解像のみをサポートし、メモリの制約により元の画像サイズに制限（512x512まで）が設けられています。この問題が解決されると、制限なしでチャンクベースの超解像を含むアップデートがおそらく行われるでしょう。",
		"to_be_continue": "つづく",
		"continue": "ACG関連の深層学習アプリケーションの開発を継続します",
		"star": "⭐⭐⭐",
		"star_detail": "acg2vec が役に立った場合は、星をクリックしてサポートしてください~",
		"acgvoc2vec_input": "ラベルを入力して類似のラベルを検索します",
		"dclip_input": "英語の説明を入力すると、その説明に一致するイラストが検索されます",
		"image_select": "クリックして画像を選択してください"
	}
}