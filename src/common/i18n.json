{
	"zh": {
		"abstract": "ACG2vec全称为Anime Comics Games to vector。将持续维护一些基于二次元相关的深度学习领域实践与探索。",
		"model_list": "模型列表",
		"acgvoc2vec_intro": "基于从维基百科动漫列表、萌娘百科、Bangumi、pixiv、AnimeList等来源获取清洗处理抽取的510w语句对微调的sentence-transformers模型，生成二次元相关文本的特征向量，用于各种下游任务（标签推荐，标签搜索，推荐系统等）可以使用<a href=\"https://huggingface.co/OysterQAQ/ACGVoc2vec\" target=\"_blank\" class=\"url\" >Huggingface</a>在线体验",
		"dclip_intro": "使用danburoo2021数据集对clip（ViT-L/14）模型进行微调。可以使用<a href=\"https://huggingface.co/OysterQAQ/DanbooruCLIP\" target=\"_blank\" class=\"url\" >Huggingface</a>在线体验。",
		"pix2score_intro": "基于ResNet101的多任务分类模型，用于分段预测动漫插图的收藏数、浏览数与情色级别。",
		"illust2vec_intro": "从<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a>模型去除预测头并对末尾层做均值池化的图片语义特征抽取模型。",
		"acgvoc2vec_detail": "使用<a href=\"https://www.sbert.net/\" target=\"_blank\" class=\"url\" >Sentence-Transformers</a>（distiluse-base-multilingual-cased-v2预训练权重），以5e-5的学习率在动漫相关多角度（翻译，问答）语句对数据集下进行微调，损失函数为MultipleNegativesRankingLoss。数据集主要包括：Bangumi、pixiv、AnimeList、维基百科、moegirl。",
		"dclip_detail": "使用<a href=\"https://gwern.net/danbooru2021\" target=\"_blank\" class=\"url\" >danburoo2021</a>数据集对<a href=\"https://github.com/openai/CLIP\" target=\"_blank\" class=\"url\" >CLIP</a>（ViT-L/14预训练权重）模型进行微调。0-3 epoch学习率为4e-6，权重衰减为1e-3、4-8 epoch学习率为1e-6，权重衰减为1e-3，最终平均loss在5e-1左右。",
		"pix2score_detail": "基于ResNet101的多任务分类模型，用于分段预测动漫插图的收藏数、浏览数与情色级别。以 1e-3 的学习率在动漫插画数据集下进行混合精度训练，输入尺寸为224x224。",
		"illust2vec_detail": "<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a>的输入层至activation_96层作为特征抽取器，均值池化后的图片语义特征抽取模型。",
		"to_be_continue": "未完待续",
		"continue": "将持续开发ACG相关深度学习应用",
		"star": "⭐⭐⭐",
		"star_detail": "如果acg2vec对你有帮助，请点个star支持一下～",
		"acgvoc2vec_input": "输入标签，搜索出近似标签",
		"dclip_input": "输入英文描述，搜索出符合描述的插画",
		"image_select": "点击选择图片"
	},
	"en": {
		"abstract": "ACG2vec, the full name of which is Anime Comics Games to Vector, will continue to maintain some practices and explorations in the field of deep learning related to ACGN (Animation, Comic, Game, Novel) content.",
		"model_list": "model list",
		"acgvoc2vec_intro": "Based on the 510 million sentences extracted, cleaned, and processed from sources like Wikipedia's anime list, Moe Girl Encyclopedia, Bangumi, pixiv, AnimeList, etc., a sentence-transformers model has been fine-tuned to generate feature vectors for ACGN content. These feature vectors can be utilized for various downstream tasks such as tag recommendation, tag search, recommendation systems, etc. You can experience the model online using the <a href=\"https://huggingface.co/OysterQAQ/ACGVoc2vec\" target=\"_blank\" class=\"url\" >Huggingface</a> platform.",
		"dclip_intro": "Using the danburoo2021 dataset to fine-tune the clip (ViT-L/14) model. You can use the <a href=\"https://huggingface.co/OysterQAQ/DanbooruCLIP\" target=\"_blank\" class=\"url\" >Huggingface</a> online experience.",
		"pix2score_intro": "A multi-task classification model based on ResNet101 is used for segmented prediction of the number of favorites, views, and the maturity level of anime illustrations.",
		"illust2vec_intro": "A model for extracting semantic image features from <a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> by removing the prediction head and applying mean pooling to the final layer.",
		"acgvoc2vec_detail": "Using <a href=\"https://www.sbert.net/\" target=\"_blank\" class=\"url\" >Sentence-Transformers</a> with the distiluse-base-multilingual-cased-v2 pretrained weights, fine-tune the model on a dataset containing anime-related multi-angle (translation, question-answering) sentence pairs with a learning rate of 5e-5. The loss function used is MultipleNegativesRankingLoss. The dataset primarily includes data from Bangumi, pixiv, AnimeList, Wikipedia, and moegirl.",
		"dclip_detail": "Using the <a href=\"https://gwern.net/danbooru2021\" target=\"_blank\" class=\"url\" >danburoo2021</a> dataset, fine-tune the <a href=\"https://github.com/openai/CLIP\" target=\"_blank\" class=\"url\" >CLIP</a> model with ViT-L/14 pretrained weights. For the first 0-3 epochs, use a learning rate of 4e-6 and weight decay of 1e-3. For the next 4-8 epochs, use a learning rate of 1e-6 and weight decay of 1e-3. The final average loss should be around 5e-1.",
		"pix2score_detail": "A multi-task classification model based on ResNet101 is used for segmented prediction of the number of favorites, views, and the maturity level of anime illustrations. The model is trained using mixed precision training with a learning rate of 1e-3 on an anime illustration dataset, and the input size is set to 224x224.",
		"illust2vec_detail": "The feature extractor of <a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> consists of the input layer up to activation_96 layer, and it serves as a model for extracting semantic image features. These features are obtained by applying mean pooling to the output of the activation_96 layer.",
		"to_be_continue": "To be continued",
		"continue": "Continuous development of ACG (Anime, Comics, Games) related deep learning applications will be pursued",
		"star": "⭐⭐⭐",
		"star_detail": "If ACG2vec has been helpful to you, please show your support by giving it a star~",
		"acgvoc2vec_input": "Input a label, search for approximate labels",
		"dclip_input": "Input an English description, search for illustrations",
		"image_select": "Click to select an image"
	},
	"jp": {
		"abstract": "ACG2vec の正式名は、アニメ・コミック・ゲーム・トゥ・ベクターです。二次元相関に基づく深層学習の分野での実践と探求は引き続き維持されます。",
		"model_list": "モデルリスト",
		"acgvoc2vec_intro": "ウィキペディアのアニメリスト、萌えガールペディア、バングミ、ピクシブ、アニメリストなどのソースから抽出した510wの文を取得してクリーニングおよび処理することで微調整された文変換モデルに基づいて、さまざまな下流向けに二次元関連テキストの特徴ベクトルが生成されます。タスク (ラベル) レコメンデーション、タグ検索、レコメンデーション システムなど) <a href=\"https://huggingface.co/OysterQAQ/ACGVoc2vec\" target=\"_blank\" class=\"url\" を使用できます>ハグフェイス</a>オンライン体験。",
		"dclip_intro": "クリップ (ViT-L/14) モデルは、danburoo2021 データセットを使用して微調整されています。 <a href=\"https://huggingface.co/OysterQAQ/DanbooruCLIP\" target=\"_blank\" class=\"url\" >Huggingface</a> を使用してオンラインで体験できます。",
		"pix2score_intro": "ResNet101 に基づくマルチタスク分類モデル。アニメーション イラストのコレクション数、閲覧数、エロレベルを部分的に予測するために使用されます。",
		"illust2vec_intro": "<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> モデルから予測ヘッドを削除し、最後の予測ヘッドを平均しますレイヤー プールされた画像セマンティック特徴抽出モデル。",
		"acgvoc2vec_detail": "<a href=\"https://www.sbert.net/\" target=\"_blank\" class=\"url\" >Sentence-Transformers</a> を使用します (distiluse-base-multilingual-cased- v2 事前トレーニング重み)、アニメーション関連のマルチアングル (翻訳、質疑応答) 文のデータセットを微調整するための学習率は 5e-5 で、損失関数は MultipleNegativesRankingLoss です。データセットには主に、バングミ、ピクシブ、アニメリスト、ウィキペディア、moegirl が含まれています。",
		"dclip_detail": "<a href=\"https://gwern.net/danbooru2021\" target=\"_blank\" class=\"url\" >danburoo2021</a> データセットを <a href=\"https:/ に使用します。 /github.com/openai/CLIP\" target=\"_blank\" class=\"url\" >CLIP</a> (ViT-L/14 事前トレーニング済み重み) モデルを微調整します。 0 ～ 3 エポックの学習レートは 4e-6、重み減衰は 1e-3、4 ～ 8 エポックの学習レートは 1e-6、重み減衰は 1e-3、最終的な平均損失は約 5e -1。",
		"pix2score_detail": "ResNet101 に基づくマルチタスク分類モデル。アニメーション イラストのコレクション数、閲覧数、エロレベルを部分的に予測するために使用されます。アニメ イラスト データセットに対する混合精度トレーニング (学習率 1e-3、入力サイズ 224x224)。",
		"illust2vec_detail": "<a href=\"https://github.com/KichangKim/DeepDanbooru\" target=\"_blank\" class=\"url\" >DeepDanbooru</a> の入力層から activity_96 層までが特徴抽出器として使用され、平均プーリング後の画像意味特徴抽出モデルとして使用されます。",
		"to_be_continue": "つづく",
		"continue": "ACG関連の深層学習アプリケーションの開発を継続します",
		"star": "⭐⭐⭐",
		"star_detail": "acg2vec が役に立った場合は、星をクリックしてサポートしてください~",
		"acgvoc2vec_input": "ラベルを入力して類似のラベルを検索します",
		"dclip_input": "英語の説明を入力すると、その説明に一致するイラストが検索されます",
		"image_select": "クリックして画像を選択してください"
	}
}